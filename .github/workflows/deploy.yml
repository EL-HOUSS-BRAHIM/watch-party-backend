name: Deploy Watch Party Backend

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:
    inputs:
      force_deploy:
        description: 'Force deployment'
        required: false
        default: false
        type: boolean

# Principle of least privilege for GHA token
permissions:
  contents: read
  id-token: write  # (Reserved if later switching to OIDC-based secrets/infra auth)
  actions: read
  checks: read

# Prevent overlapping deployments on same branch
concurrency:
  group: deploy-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.12'

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: >-
      (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || github.event.inputs.force_deploy == 'true') && github.event_name != 'pull_request'
    outputs:
      deployment_ready: ${{ steps.check_deployment.outputs.ready }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python (for validation / lock)
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements.txt
      - name: Validate workflow inputs
        id: validate
        run: |
          echo "force_deploy=${{ github.event.inputs.force_deploy || 'false' }}"
      - name: Check deployment readiness
        id: check_deployment
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" || "${{ github.ref }}" == "refs/heads/master" || "${{ github.event.inputs.force_deploy }}" == "true" ]]; then
            echo "ready=true" >> $GITHUB_OUTPUT
          else
            echo "ready=false" >> $GITHUB_OUTPUT
          fi
      - name: Freeze dependencies (for traceability)
        if: steps.check_deployment.outputs.ready == 'true'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip freeze > requirements.freeze.txt
      - name: Create deployment package
        if: steps.check_deployment.outputs.ready == 'true'
        run: |
          mkdir -p deployment-package
          rsync -av --exclude='.git' \
                    --exclude='*.pyc' \
                    --exclude='__pycache__' \
                    --exclude='.pytest_cache' \
                    --exclude='node_modules' \
                    --exclude='.env' \
                    --exclude='db.sqlite3' \
                    --exclude='logs' \
                    --exclude='.coverage' \
                    --exclude='htmlcov' \
                    --exclude='*.log' \
                    --exclude='.vscode' \
                    --exclude='.idea' \
                    ./ deployment-package/
          # Copy optional env/example files only if present
          for f in .env.example .env.production; do
            if [[ -f "$f" ]]; then
              cp "$f" deployment-package/
            else
              echo "$f not found, skipping"
            fi
          done
          cp requirements.freeze.txt deployment-package/ 2>/dev/null || true
          if [[ -f .env ]]; then
            grep -Ev '^(SECRET_KEY=|DATABASE_URL=postgresql://watchparty_admin:|REDIS_URL=rediss://|DATABASE_PASSWORD=|REDIS_PASSWORD=)' .env > deployment-package/.env.template || true
          fi
          cat > deployment-package/deployment-info.json <<'JSON'
          {
            "commit_sha": "${{ github.sha }}",
            "commit_message": "$(echo "$(git log -1 --pretty=%B | head -1)" | sed 's/"/\\"/g')",
            "branch": "${{ github.ref_name }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "actor": "${{ github.actor }}",
            "run_id": "${{ github.run_id }}"
          }
          JSON
      - name: Generate checksums
        if: steps.check_deployment.outputs.ready == 'true'
        run: |
          # Recreate checksum file deterministically; exclude itself & CI/meta files
          (cd deployment-package && \
            rm -f CHECKSUMS.sha256 && \
            find . -type f -maxdepth 8 \
              ! -name 'CHECKSUMS.sha256' \
              ! -path './.github/*' \
              ! -path './logs/*' \
              ! -path './**/__pycache__/*' \
              ! -name '*.pyc' \
              -print0 | sort -z | xargs -0 sha256sum > CHECKSUMS.sha256)
      - name: Upload deployment package
        if: steps.check_deployment.outputs.ready == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: deployment-package
          path: deployment-package/
          retention-days: 30

  deploy:
    needs: [build]
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: needs.build.outputs.deployment_ready == 'true'
    environment: production
    steps:
      - name: Checkout code (for remote script)
        uses: actions/checkout@v4
      - name: Download deployment package
        uses: actions/download-artifact@v4
        with:
          name: deployment-package
          path: deployment-package/
      - name: Verify checksums
        run: |
          cd deployment-package
          if [[ ! -f CHECKSUMS.sha256 ]]; then
            echo "No checksum file present, skipping verification"
            exit 0
          fi
          # Filter out any entries whose files are absent (e.g., intentionally excluded on deploy)
          TMP_FILE=$(mktemp)
          while read -r hash path; do
            # path comes like: <hash><space><space>./relative
            file=${path#./}
            if [[ -f "$file" ]]; then
              printf '%s  %s\n' "$hash" "$path" >> "$TMP_FILE"
            else
              echo "Skipping missing $path"
            fi
          done < CHECKSUMS.sha256
          if [[ ! -s "$TMP_FILE" ]]; then
            echo "No files left to verify; skipping"
            exit 0
          fi
          sha256sum -c "$TMP_FILE" || { echo "Checksum mismatch(s) detected"; exit 1; }
      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
      - name: Generate production .env (sanitized) locally
        env:
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          ALLOWED_HOSTS: ${{ secrets.ALLOWED_HOSTS }}
          CSRF_TRUSTED_ORIGINS: ${{ secrets.CSRF_TRUSTED_ORIGINS }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          CELERY_BROKER_URL: ${{ secrets.CELERY_BROKER_URL }}
          CELERY_RESULT_BACKEND: ${{ secrets.CELERY_RESULT_BACKEND }}
          CHANNEL_LAYERS_CONFIG_HOSTS: ${{ secrets.CHANNEL_LAYERS_CONFIG_HOSTS }}
          DEFAULT_FROM_EMAIL: ${{ secrets.DEFAULT_FROM_EMAIL }}
        run: |
          OUT=deployment-package/.env.generated
          : > "$OUT"
          echo "SECRET_KEY=$SECRET_KEY" >> "$OUT"
          echo "DJANGO_SETTINGS_MODULE=watchparty.settings.production" >> "$OUT"
          echo "ALLOWED_HOSTS=$ALLOWED_HOSTS" >> "$OUT"
          echo "CSRF_TRUSTED_ORIGINS=$CSRF_TRUSTED_ORIGINS" >> "$OUT"
          echo "DATABASE_URL=$DATABASE_URL" >> "$OUT"
          echo "REDIS_URL=$REDIS_URL" >> "$OUT"
          echo "CELERY_BROKER_URL=$CELERY_BROKER_URL" >> "$OUT"
          echo "CELERY_RESULT_BACKEND=$CELERY_RESULT_BACKEND" >> "$OUT"
          echo "CHANNEL_LAYERS_CONFIG_HOSTS=$CHANNEL_LAYERS_CONFIG_HOSTS" >> "$OUT"
          echo "DEFAULT_FROM_EMAIL=$DEFAULT_FROM_EMAIL" >> "$OUT"
          if [[ -n "${SENTRY_DSN:-}" ]]; then echo "SENTRY_DSN=$SENTRY_DSN" >> "$OUT"; fi
          echo "ENVIRONMENT=production" >> "$OUT"
          echo "DEBUG=False" >> "$OUT"
          echo "RATE_LIMIT_ENABLED=True" >> "$OUT"
      - name: Prepare remote deploy script
        env:
          SERVER_USER: ${{ secrets.SERVER_USER }}
        run: |
          cat > ci_remote_deploy.sh << 'SCRIPT'
          #!/bin/bash
          set -euo pipefail
          umask 022

          DEPLOY_DIR="${DEPLOY_DIR:-/var/www/watch-party-backend}"
          SERVICE_USER="${SERVER_USER:-www-data}"
          SERVICE_GROUP="www-data"

          echo "$(date): 🔧 Starting server environment setup..."
          echo "Deploy directory: $DEPLOY_DIR"
          echo "Service user: $SERVICE_USER"

          # Detect package manager
          if command -v apt-get >/dev/null 2>&1; then
            sudo apt-get update -qq || true
            INSTALLER="apt-get install -y"
          elif command -v yum >/dev/null 2>&1; then
            sudo yum -y -q update || true
            INSTALLER="yum install -y"
          elif command -v dnf >/dev/null 2>&1; then
            sudo dnf -y -q update || true
            INSTALLER="dnf install -y"
          else
            echo "Unsupported package manager"; exit 1
          fi

          echo "Installing base packages (idempotent)"
          if command -v apt-get >/dev/null 2>&1; then
            sudo apt-get install -y python3 python3-venv python3-pip python3-dev build-essential libpq-dev rsync curl git || true
          else
            sudo $INSTALLER python3 python3-pip rsync curl git || true
          fi

          # Create service user if missing
          if ! id "$SERVICE_USER" >/dev/null 2>&1; then
            sudo useradd -r -s /usr/sbin/nologin -d /var/www -c "WatchParty Service User" "$SERVICE_USER" || true
          fi

          # Directory setup & ownership BEFORE rsync
          sudo mkdir -p "$DEPLOY_DIR" /var/log/watchparty
          sudo chown -R $SERVICE_USER:$SERVICE_GROUP "$DEPLOY_DIR" /var/log/watchparty
          # Ensure application log directory exists
          sudo mkdir -p "$DEPLOY_DIR/logs"
          sudo touch "$DEPLOY_DIR/logs/django.log"
          sudo chown -R $SERVICE_USER:$SERVICE_GROUP "$DEPLOY_DIR/logs"
          sudo chmod 664 "$DEPLOY_DIR/logs/django.log" || true

          echo "📤 Syncing project files to $DEPLOY_DIR";
          sudo rsync -av --delete --exclude='venv' --exclude='.env' --chown=$SERVICE_USER:$SERVICE_GROUP ./ "$DEPLOY_DIR/"

          # Place env file if provided
          if [[ -f ./.env.generated && ! -f "$DEPLOY_DIR/.env" ]]; then
            sudo mv ./.env.generated "$DEPLOY_DIR/.env"
            sudo chmod 600 "$DEPLOY_DIR/.env"
            sudo chown $SERVICE_USER:$SERVICE_GROUP "$DEPLOY_DIR/.env"
          fi

          cd "$DEPLOY_DIR"
          echo "🔧 Ensuring clean & writable virtual environment"
          if [[ -d venv ]]; then
            OWNER=$(stat -c %U venv || echo unknown)
            if [[ "$OWNER" != "$SERVICE_USER" ]]; then
              echo "Existing venv owned by $OWNER; removing with sudo"
              sudo rm -rf venv || { echo "Failed to remove existing venv"; exit 1; }
            elif [[ ! -w venv/bin/python* ]]; then
              echo "Existing venv not writable; removing"
              sudo rm -rf venv || { echo "Failed to remove unwritable venv"; exit 1; }
            fi
          fi
          if [[ -d venv && ! -f venv/bin/activate ]]; then
            echo "Corrupted venv detected; removing"
            sudo rm -rf venv || { echo "Failed to remove corrupted venv"; exit 1; }
          fi
          if [[ ! -d venv ]]; then
            echo "Creating venv as $SERVICE_USER"
            sudo -u $SERVICE_USER -H python3 -m venv venv || { echo "Failed to create venv"; exit 1; }
          fi
          sudo chown -R $SERVICE_USER:$SERVICE_GROUP venv || true
          # Verify site-packages writable
          sudo -u $SERVICE_USER -H bash -c 'python - <<PY\nimport sys,os,glob;\nsp=[p for p in sys.path if p.endswith("site-packages")];\nsp=sp[0] if sp else "";\nprint("Site-packages:", sp);\nexit(0 if (sp and os.access(sp, os.W_OK)) else 1)\nPY' || { echo "site-packages not writable for $SERVICE_USER"; ls -ld venv/lib/python*/site-packages || true; exit 1; }

          echo "📦 Installing Python dependencies as $SERVICE_USER"
          sudo -u $SERVICE_USER -H bash -c 'source venv/bin/activate && python -m ensurepip --upgrade || true && pip install --upgrade pip setuptools wheel && pip install -r requirements.txt && pip install gunicorn gevent'

          echo "🗄 Running migrations & collectstatic"
          sudo -u $SERVICE_USER -H bash -c 'source venv/bin/activate && python manage.py migrate --noinput || true && python manage.py collectstatic --noinput || true'

          # Systemd service creation (idempotent)
          if [[ ! -f /etc/systemd/system/watchparty-gunicorn.service ]]; then
            cat > /tmp/watchparty-gunicorn.service << EOF
          [Unit]
          Description=Watch Party Gunicorn Application Server
          After=network.target

          [Service]
          Type=simple
          User=$SERVICE_USER
          Group=$SERVICE_GROUP
          WorkingDirectory=$DEPLOY_DIR
          EnvironmentFile=$DEPLOY_DIR/.env
          ExecStart=$DEPLOY_DIR/venv/bin/gunicorn --bind 127.0.0.1:8000 --workers 3 --worker-class gevent --access-logfile /var/log/watchparty/access.log --error-logfile /var/log/watchparty/error.log watchparty.wsgi:application
          Restart=on-failure
          RestartSec=5
          KillMode=mixed
          TimeoutStopSec=10
          PrivateTmp=true

          [Install]
          WantedBy=multi-user.target
          EOF
            sudo mv /tmp/watchparty-gunicorn.service /etc/systemd/system/watchparty-gunicorn.service
            sudo systemctl daemon-reload
            sudo systemctl enable watchparty-gunicorn
          fi

          sudo systemctl restart watchparty-gunicorn || sudo systemctl start watchparty-gunicorn

          echo "Health check"
          curl -f http://127.0.0.1:8000/health/ >/dev/null 2>&1 && echo "App OK" || echo "App health failed"
          SCRIPT
          chmod +x ci_remote_deploy.sh
      - name: Deploy to server
        env:
          SERVER_HOST: ${{ secrets.SERVER_HOST }}
          SERVER_USER: ${{ secrets.SERVER_USER }}
          PROJECT_DIR: ${{ secrets.PROJECT_DIR }}
        timeout-minutes: 30
        run: |
          FALLBACK_DIR="/var/www/watch-party-backend"
          TARGET_DIR="${PROJECT_DIR:-$FALLBACK_DIR}"
          
          echo "🚀 Starting deployment to $SERVER_HOST..."
          echo "Target directory: $TARGET_DIR"
          
          # Test SSH connection first
          echo "🔗 Testing SSH connection..."
          if ! ssh -o ConnectTimeout=10 -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_HOST "echo 'SSH connection successful'"; then
            echo "❌ SSH connection failed"
            exit 1
          fi
          
          # Clean up and prepare remote directory
          echo "🧹 Preparing remote directory..."
          ssh $SERVER_USER@$SERVER_HOST "rm -rf /tmp/watchparty-deploy && mkdir -p /tmp/watchparty-deploy"
          
          # Upload files with progress
          echo "📤 Uploading deployment files..."
          scp -o StrictHostKeyChecking=no -r deployment-package/* $SERVER_USER@$SERVER_HOST:/tmp/watchparty-deploy/
          scp -o StrictHostKeyChecking=no ci_remote_deploy.sh $SERVER_USER@$SERVER_HOST:/tmp/watchparty-deploy/
          
          # Execute deployment with timeout
          echo "⚙️ Executing remote deployment script..."
          ssh -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_HOST "cd /tmp/watchparty-deploy && timeout 1200 bash -x ./ci_remote_deploy.sh" || {
            echo "❌ Deployment script failed or timed out"
            echo "🔍 Checking for any error logs..."
            ssh $SERVER_USER@$SERVER_HOST "tail -50 /var/log/watchparty/error.log 2>/dev/null || echo 'No error log found yet'"
            exit 1
          }
          
          echo "✅ Remote deployment completed successfully"
      - name: Post-deployment verification
        env:
          SERVER_HOST: ${{ secrets.SERVER_HOST }}
          SERVER_USER: ${{ secrets.SERVER_USER }}
        run: |
          echo "🔍 Running post-deployment verification..."
          
          # Wait a moment for services to stabilize
          sleep 10
          
          # Check service status
          echo "Checking systemd services..."
          ssh $SERVER_USER@$SERVER_HOST "
            echo '=== Gunicorn Service Status ==='
            sudo systemctl status watchparty-gunicorn --no-pager -l || true
            echo
            echo '=== Nginx Service Status ==='
            sudo systemctl status nginx --no-pager -l || true
            echo
            echo '=== Recent Logs ==='
            tail -20 /var/log/watchparty/error.log 2>/dev/null || echo 'No error log found'
          "
          
          # Test endpoints
          echo "Testing application endpoints..."
          if ssh $SERVER_USER@$SERVER_HOST "curl -f -m 10 http://127.0.0.1:8000/health/ >/dev/null 2>&1"; then
            echo "✅ Direct application health check passed"
          else
            echo "⚠️ Direct application health check failed"
          fi
          
          if ssh $SERVER_USER@$SERVER_HOST "curl -f -m 10 http://127.0.0.1/health/ >/dev/null 2>&1"; then
            echo "✅ Nginx proxy health check passed"
          else
            echo "⚠️ Nginx proxy health check failed"
          fi
      - name: Notify deployment status
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "✅ Deployment completed successfully"
          else
            echo "❌ Deployment failed"
          fi
  cleanup:
    needs: [deploy]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Cleanup
        run: |
          echo "Workflow finished for commit ${{ github.sha }}"
